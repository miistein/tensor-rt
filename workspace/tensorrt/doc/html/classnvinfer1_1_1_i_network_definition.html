<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>TensorRT: nvinfer1::INetworkDefinition Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">TensorRT
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classnvinfer1_1_1_i_network_definition.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classnvinfer1_1_1_i_network_definition-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">nvinfer1::INetworkDefinition Class Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>A network definition for input to the builder.  
 <a href="classnvinfer1_1_1_i_network_definition.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_nv_infer_8h_source.html">NvInfer.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a06a61f560bdf6197afd3368937f62025"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a06a61f560bdf6197afd3368937f62025">addInput</a> (const char *name, <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217">DataType</a> type, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> dimensions)=0</td></tr>
<tr class="memdesc:a06a61f560bdf6197afd3368937f62025"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an input tensor to the network.  <a href="#a06a61f560bdf6197afd3368937f62025">More...</a><br/></td></tr>
<tr class="separator:a06a61f560bdf6197afd3368937f62025"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d2cdec24bc4a1507fc80f100e18cfe9"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a5d2cdec24bc4a1507fc80f100e18cfe9">markOutput</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;tensor)=0</td></tr>
<tr class="memdesc:a5d2cdec24bc4a1507fc80f100e18cfe9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mark a tensor as a network output.  <a href="#a5d2cdec24bc4a1507fc80f100e18cfe9">More...</a><br/></td></tr>
<tr class="separator:a5d2cdec24bc4a1507fc80f100e18cfe9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29fb055009bb117be0e957cd1bce44a9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_convolution_layer.html">IConvolutionLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a29fb055009bb117be0e957cd1bce44a9">addConvolution</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputMaps, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> kernelSize, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a29fb055009bb117be0e957cd1bce44a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a convolution layer to the network.  <a href="#a29fb055009bb117be0e957cd1bce44a9">More...</a><br/></td></tr>
<tr class="separator:a29fb055009bb117be0e957cd1bce44a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411e2cefb9a4307d99fcc442c2a708a8"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_fully_connected_layer.html">IFullyConnectedLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a411e2cefb9a4307d99fcc442c2a708a8">addFullyConnected</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputs, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a411e2cefb9a4307d99fcc442c2a708a8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a fully connected layer to the network.  <a href="#a411e2cefb9a4307d99fcc442c2a708a8">More...</a><br/></td></tr>
<tr class="separator:a411e2cefb9a4307d99fcc442c2a708a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0382282a59e3841726f6c29c4ac1f684"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_activation_layer.html">IActivationLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a0382282a59e3841726f6c29c4ac1f684">addActivation</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#acbd177748000d30ae0277ee980757eb6">ActivationType</a> type)=0</td></tr>
<tr class="memdesc:a0382282a59e3841726f6c29c4ac1f684"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an activation layer to the network.  <a href="#a0382282a59e3841726f6c29c4ac1f684">More...</a><br/></td></tr>
<tr class="separator:a0382282a59e3841726f6c29c4ac1f684"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49459eaa7e1bbff5371365f125c2f0c5"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_pooling_layer.html">IPoolingLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a49459eaa7e1bbff5371365f125c2f0c5">addPooling</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14">PoolingType</a> type, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> windowSize)=0</td></tr>
<tr class="memdesc:a49459eaa7e1bbff5371365f125c2f0c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a pooling layer to the network.  <a href="#a49459eaa7e1bbff5371365f125c2f0c5">More...</a><br/></td></tr>
<tr class="separator:a49459eaa7e1bbff5371365f125c2f0c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1c8386fd389fd74b0b48121d22abc67"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_l_r_n_layer.html">ILRNLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa1c8386fd389fd74b0b48121d22abc67">addLRN</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int window, float alpha, float beta, float k)=0</td></tr>
<tr class="memdesc:aa1c8386fd389fd74b0b48121d22abc67"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a LRN layer to the network.  <a href="#aa1c8386fd389fd74b0b48121d22abc67">More...</a><br/></td></tr>
<tr class="separator:aa1c8386fd389fd74b0b48121d22abc67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37cf24c7c620aa661de167f302559289"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_scale_layer.html">IScaleLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a37cf24c7c620aa661de167f302559289">addScale</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0">ScaleMode</a> mode, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> shift, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> scale, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> power)=0</td></tr>
<tr class="memdesc:a37cf24c7c620aa661de167f302559289"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a Scale layer to the network.  <a href="#a37cf24c7c620aa661de167f302559289">More...</a><br/></td></tr>
<tr class="separator:a37cf24c7c620aa661de167f302559289"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a595af67528bf0664afa9815114933320"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_soft_max_layer.html">ISoftMaxLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a595af67528bf0664afa9815114933320">addSoftMax</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:a595af67528bf0664afa9815114933320"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a SoftMax layer to the network.  <a href="#a595af67528bf0664afa9815114933320">More...</a><br/></td></tr>
<tr class="separator:a595af67528bf0664afa9815114933320"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80d81ac3ebb81efbd3a29d4c9f5c3a72"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_concatenation_layer.html">IConcatenationLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a80d81ac3ebb81efbd3a29d4c9f5c3a72">addConcatenation</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs)=0</td></tr>
<tr class="memdesc:a80d81ac3ebb81efbd3a29d4c9f5c3a72"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a concatenation layer to the network.  <a href="#a80d81ac3ebb81efbd3a29d4c9f5c3a72">More...</a><br/></td></tr>
<tr class="separator:a80d81ac3ebb81efbd3a29d4c9f5c3a72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80f985a0a5e5e68561ef205bf346fc33"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html">IDeconvolutionLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a80f985a0a5e5e68561ef205bf346fc33">addDeconvolution</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputMaps, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> kernelSize, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a80f985a0a5e5e68561ef205bf346fc33"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a deconvolution layer to the network.  <a href="#a80f985a0a5e5e68561ef205bf346fc33">More...</a><br/></td></tr>
<tr class="separator:a80f985a0a5e5e68561ef205bf346fc33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa12fda7cb22a7a12f4d58701e9f3988f"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_element_wise_layer.html">IElementWiseLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa12fda7cb22a7a12f4d58701e9f3988f">addElementWise</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input1, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input2, <a class="el" href="namespacenvinfer1.html#a9badc834875b5c57d9556a66e5e20978">ElementWiseOperation</a> op)=0</td></tr>
<tr class="memdesc:aa12fda7cb22a7a12f4d58701e9f3988f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an elementwise layer to the network.  <a href="#aa12fda7cb22a7a12f4d58701e9f3988f">More...</a><br/></td></tr>
<tr class="separator:aa12fda7cb22a7a12f4d58701e9f3988f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ed8d1ed43046a041a90ad579fad5a20"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html">IRNNLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a0ed8d1ed43046a041a90ad579fad5a20">addRNN</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;inputs, int layerCount, std::size_t hiddenSize, int maxSeqLen, <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a> op, <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fd">RNNInputMode</a> mode, <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8">RNNDirection</a> dir, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> weights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> bias)=0</td></tr>
<tr class="memdesc:a0ed8d1ed43046a041a90ad579fad5a20"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an <code>layerCount</code> deep RNN layer to the network with a sequence length of <code>maxSeqLen</code> and <code>hiddenSize</code> internal state per layer.  <a href="#a0ed8d1ed43046a041a90ad579fad5a20">More...</a><br/></td></tr>
<tr class="separator:a0ed8d1ed43046a041a90ad579fad5a20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b31ce474ba291e1c95e39ab13c76942"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4b31ce474ba291e1c95e39ab13c76942">addPlugin</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs, <a class="el" href="classnvinfer1_1_1_i_plugin.html">IPlugin</a> &amp;plugin)=0</td></tr>
<tr class="memdesc:a4b31ce474ba291e1c95e39ab13c76942"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a plugin layer to the network.  <a href="#a4b31ce474ba291e1c95e39ab13c76942">More...</a><br/></td></tr>
<tr class="separator:a4b31ce474ba291e1c95e39ab13c76942"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b85bd3f05c234fcc1118f827d7c0720"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_unary_layer.html">IUnaryLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4b85bd3f05c234fcc1118f827d7c0720">addUnary</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aeaeaae08a730508ead278d52b8517a09">UnaryOperation</a> operation)=0</td></tr>
<tr class="memdesc:a4b85bd3f05c234fcc1118f827d7c0720"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a unary layer to the network.  <a href="#a4b85bd3f05c234fcc1118f827d7c0720">More...</a><br/></td></tr>
<tr class="separator:a4b85bd3f05c234fcc1118f827d7c0720"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a334d849cb8720a8a66a95fc84487b132"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_padding_layer.html">IPaddingLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a334d849cb8720a8a66a95fc84487b132">addPadding</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> prePadding, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> postPadding)=0</td></tr>
<tr class="memdesc:a334d849cb8720a8a66a95fc84487b132"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a padding layer to the network.  <a href="#a334d849cb8720a8a66a95fc84487b132">More...</a><br/></td></tr>
<tr class="separator:a334d849cb8720a8a66a95fc84487b132"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2628a97544b7802076246069321e2bf9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_shuffle_layer.html">IShuffleLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a2628a97544b7802076246069321e2bf9">addShuffle</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:a2628a97544b7802076246069321e2bf9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a shuffle layer to the network.  <a href="#a2628a97544b7802076246069321e2bf9">More...</a><br/></td></tr>
<tr class="separator:a2628a97544b7802076246069321e2bf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8311e3c0c99f0d058bc195b0f8f4878"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ad8311e3c0c99f0d058bc195b0f8f4878">setPoolingOutputDimensionsFormula</a> (<a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *formula)=0</td></tr>
<tr class="memdesc:ad8311e3c0c99f0d058bc195b0f8f4878"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the pooling output dimensions formula.  <a href="#ad8311e3c0c99f0d058bc195b0f8f4878">More...</a><br/></td></tr>
<tr class="separator:ad8311e3c0c99f0d058bc195b0f8f4878"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6700a429213bf8ae37472ca5b687dbb2"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6700a429213bf8ae37472ca5b687dbb2">getPoolingOutputDimensionsFormula</a> () const =0</td></tr>
<tr class="memdesc:a6700a429213bf8ae37472ca5b687dbb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the pooling output dimensions formula.  <a href="#a6700a429213bf8ae37472ca5b687dbb2">More...</a><br/></td></tr>
<tr class="separator:a6700a429213bf8ae37472ca5b687dbb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5516b9c8061a0d44ef13568637a173a"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa5516b9c8061a0d44ef13568637a173a">setConvolutionOutputDimensionsFormula</a> (<a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *formula)=0</td></tr>
<tr class="memdesc:aa5516b9c8061a0d44ef13568637a173a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the convolution output dimensions formula.  <a href="#aa5516b9c8061a0d44ef13568637a173a">More...</a><br/></td></tr>
<tr class="separator:aa5516b9c8061a0d44ef13568637a173a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a355de31bece2776d8ca5866ad38db40f"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a355de31bece2776d8ca5866ad38db40f">getConvolutionOutputDimensionsFormula</a> () const =0</td></tr>
<tr class="memdesc:a355de31bece2776d8ca5866ad38db40f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the convolution output dimensions formula.  <a href="#a355de31bece2776d8ca5866ad38db40f">More...</a><br/></td></tr>
<tr class="separator:a355de31bece2776d8ca5866ad38db40f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9d58a40de209963d4ea5e733c9b16c1"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac9d58a40de209963d4ea5e733c9b16c1">setDeconvolutionOutputDimensionsFormula</a> (<a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *formula)=0</td></tr>
<tr class="memdesc:ac9d58a40de209963d4ea5e733c9b16c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the deconvolution output dimensions formula.  <a href="#ac9d58a40de209963d4ea5e733c9b16c1">More...</a><br/></td></tr>
<tr class="separator:ac9d58a40de209963d4ea5e733c9b16c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0470c5b3b58464083ed2d10ed52c2049"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a0470c5b3b58464083ed2d10ed52c2049">getDeconvolutionOutputDimensionsFormula</a> () const =0</td></tr>
<tr class="memdesc:a0470c5b3b58464083ed2d10ed52c2049"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the deconvolution output dimensions formula.  <a href="#a0470c5b3b58464083ed2d10ed52c2049">More...</a><br/></td></tr>
<tr class="separator:a0470c5b3b58464083ed2d10ed52c2049"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a191a7724fc0c03a3b6f5fd8782dcd30e"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a191a7724fc0c03a3b6f5fd8782dcd30e">getNbLayers</a> () const =0</td></tr>
<tr class="memdesc:a191a7724fc0c03a3b6f5fd8782dcd30e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of layers in the network.  <a href="#a191a7724fc0c03a3b6f5fd8782dcd30e">More...</a><br/></td></tr>
<tr class="separator:a191a7724fc0c03a3b6f5fd8782dcd30e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a81749aaa08e93ca4ae1dbb1739c7bd"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_layer.html">ILayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4a81749aaa08e93ca4ae1dbb1739c7bd">getLayer</a> (int index) const =0</td></tr>
<tr class="memdesc:a4a81749aaa08e93ca4ae1dbb1739c7bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the layer specified by the given index.  <a href="#a4a81749aaa08e93ca4ae1dbb1739c7bd">More...</a><br/></td></tr>
<tr class="separator:a4a81749aaa08e93ca4ae1dbb1739c7bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7a0538c92b9850b3ecd939609759cdd"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac7a0538c92b9850b3ecd939609759cdd">getNbInputs</a> () const =0</td></tr>
<tr class="memdesc:ac7a0538c92b9850b3ecd939609759cdd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of inputs in the network.  <a href="#ac7a0538c92b9850b3ecd939609759cdd">More...</a><br/></td></tr>
<tr class="separator:ac7a0538c92b9850b3ecd939609759cdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaecdd8775e0ce4643112932f721f93c1"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aaecdd8775e0ce4643112932f721f93c1">getInput</a> (int index) const =0</td></tr>
<tr class="memdesc:aaecdd8775e0ce4643112932f721f93c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the input tensor specified by the given index.  <a href="#aaecdd8775e0ce4643112932f721f93c1">More...</a><br/></td></tr>
<tr class="separator:aaecdd8775e0ce4643112932f721f93c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1eb3e1df9e652363d7ab4e3796794bb2"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a1eb3e1df9e652363d7ab4e3796794bb2">getNbOutputs</a> () const =0</td></tr>
<tr class="memdesc:a1eb3e1df9e652363d7ab4e3796794bb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of outputs in the network.  <a href="#a1eb3e1df9e652363d7ab4e3796794bb2">More...</a><br/></td></tr>
<tr class="separator:a1eb3e1df9e652363d7ab4e3796794bb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6eb45e378bf2b2097da64e3886010bd0"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6eb45e378bf2b2097da64e3886010bd0">getOutput</a> (int index) const =0</td></tr>
<tr class="memdesc:a6eb45e378bf2b2097da64e3886010bd0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the output tensor specified by the given index.  <a href="#a6eb45e378bf2b2097da64e3886010bd0">More...</a><br/></td></tr>
<tr class="separator:a6eb45e378bf2b2097da64e3886010bd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42e5fd7a24306239e67168435a800515"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42e5fd7a24306239e67168435a800515"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a42e5fd7a24306239e67168435a800515">destroy</a> ()=0</td></tr>
<tr class="memdesc:a42e5fd7a24306239e67168435a800515"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroy this <a class="el" href="classnvinfer1_1_1_i_network_definition.html" title="A network definition for input to the builder. ">INetworkDefinition</a> object. <br/></td></tr>
<tr class="separator:a42e5fd7a24306239e67168435a800515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41437aa7107e61b82c5f3490984bf011"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_reduce_layer.html">IReduceLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a41437aa7107e61b82c5f3490984bf011">addReduce</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#a6640220fcbd633240524ba27b5c6c7e7">ReduceOperation</a> operation, uint32_t reduceAxes, bool keepDimensions)=0</td></tr>
<tr class="memdesc:a41437aa7107e61b82c5f3490984bf011"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a reduce layer to the network.  <a href="#a41437aa7107e61b82c5f3490984bf011">More...</a><br/></td></tr>
<tr class="separator:a41437aa7107e61b82c5f3490984bf011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a384a409318bf416be3aa4442f2b0ce76"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_top_k_layer.html">ITopKLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a384a409318bf416be3aa4442f2b0ce76">addTopK</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#a1323342950a2702ba66e29c64404a7f3">TopKOperation</a> op, int k, uint32_t reduceAxes)=0</td></tr>
<tr class="memdesc:a384a409318bf416be3aa4442f2b0ce76"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a TopK layer to the network.  <a href="#a384a409318bf416be3aa4442f2b0ce76">More...</a><br/></td></tr>
<tr class="separator:a384a409318bf416be3aa4442f2b0ce76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81ea0b5ce4a6a24e8e4953fd0e0b3216"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_gather_layer.html">IGatherLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a81ea0b5ce4a6a24e8e4953fd0e0b3216">addGather</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;data, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;indices, int axis)=0</td></tr>
<tr class="memdesc:a81ea0b5ce4a6a24e8e4953fd0e0b3216"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a gather layer to the network.  <a href="#a81ea0b5ce4a6a24e8e4953fd0e0b3216">More...</a><br/></td></tr>
<tr class="separator:a81ea0b5ce4a6a24e8e4953fd0e0b3216"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea842c9f897201eb855ce164944e9110"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_ragged_soft_max_layer.html">IRaggedSoftMaxLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aea842c9f897201eb855ce164944e9110">addRaggedSoftMax</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;bounds)=0</td></tr>
<tr class="memdesc:aea842c9f897201eb855ce164944e9110"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a RaggedSoftMax layer to the network.  <a href="#aea842c9f897201eb855ce164944e9110">More...</a><br/></td></tr>
<tr class="separator:aea842c9f897201eb855ce164944e9110"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a434fd652b4b5d09cb2462d169d63044c"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html">IMatrixMultiplyLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a434fd652b4b5d09cb2462d169d63044c">addMatrixMultiply</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input0, bool transpose0, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input1, bool transpose1)=0</td></tr>
<tr class="memdesc:a434fd652b4b5d09cb2462d169d63044c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a MatrixMultiply layer to the network.  <a href="#a434fd652b4b5d09cb2462d169d63044c">More...</a><br/></td></tr>
<tr class="separator:a434fd652b4b5d09cb2462d169d63044c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec3314208c6d807cb572cd7d336bf5ed"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_constant_layer.html">IConstantLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aec3314208c6d807cb572cd7d336bf5ed">addConstant</a> (<a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> dimensions, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> weights)=0</td></tr>
<tr class="memdesc:aec3314208c6d807cb572cd7d336bf5ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a constant layer to the network.  <a href="#aec3314208c6d807cb572cd7d336bf5ed">More...</a><br/></td></tr>
<tr class="separator:aec3314208c6d807cb572cd7d336bf5ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cd3869f7406f73261857987be1b18a9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html">IRNNv2Layer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6cd3869f7406f73261857987be1b18a9">addRNNv2</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int32_t layerCount, int32_t hiddenSize, int32_t maxSeqLen, <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a> op)=0</td></tr>
<tr class="memdesc:a6cd3869f7406f73261857987be1b18a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an <code>layerCount</code> deep RNN layer to the network with <code>hiddenSize</code> internal states that can take a batch with fixed or variable sequence lengths.  <a href="#a6cd3869f7406f73261857987be1b18a9">More...</a><br/></td></tr>
<tr class="separator:a6cd3869f7406f73261857987be1b18a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1a2e299546ea7e803b88a4fdbd8f807"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac1a2e299546ea7e803b88a4fdbd8f807">addPluginExt</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs, <a class="el" href="classnvinfer1_1_1_i_plugin_ext.html">IPluginExt</a> &amp;plugin)=0</td></tr>
<tr class="memdesc:ac1a2e299546ea7e803b88a4fdbd8f807"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a plugin layer to the network using an <a class="el" href="classnvinfer1_1_1_i_plugin_ext.html" title="Plugin class for user-implemented layers. ">IPluginExt</a> interface.  <a href="#ac1a2e299546ea7e803b88a4fdbd8f807">More...</a><br/></td></tr>
<tr class="separator:ac1a2e299546ea7e803b88a4fdbd8f807"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>A network definition for input to the builder. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a0382282a59e3841726f6c29c4ac1f684"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_activation_layer.html">IActivationLayer</a>* nvinfer1::INetworkDefinition::addActivation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#acbd177748000d30ae0277ee980757eb6">ActivationType</a>&#160;</td>
          <td class="paramname"><em>type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an activation layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">type</td><td>The type of activation function to apply.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_activation_layer.html" title="An Activation layer in a network definition. ">IActivationLayer</a> <a class="el" href="namespacenvinfer1.html#acbd177748000d30ae0277ee980757eb6" title="Enumerates the types of activation to perform in an activation layer. ">ActivationType</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new activation layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a80d81ac3ebb81efbd3a29d4c9f5c3a72"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_concatenation_layer.html">IConcatenationLayer</a>* nvinfer1::INetworkDefinition::addConcatenation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a concatenation layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_concatenation_layer.html" title="A concatenation layer in a network definition. ">IConcatenationLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new concatenation layer, or null if it could not be created.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>All tensors must have the same dimensions for all dimensions except for channel. </dd></dl>

</div>
</div>
<a class="anchor" id="aec3314208c6d807cb572cd7d336bf5ed"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_constant_layer.html">IConstantLayer</a>* nvinfer1::INetworkDefinition::addConstant </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>dimensions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>weights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a constant layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dimensions</td><td>The dimensions of the constant. </td></tr>
    <tr><td class="paramname">weights</td><td>The constant value, represented as weights.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_constant_layer.html" title="Layer that represents a constant value. ">IConstantLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new constant layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a29fb055009bb117be0e957cd1bce44a9"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_convolution_layer.html">IConvolutionLayer</a>* nvinfer1::INetworkDefinition::addConvolution </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputMaps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>kernelSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a convolution layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the convolution. </td></tr>
    <tr><td class="paramname">nbOutputMaps</td><td>The number of output feature maps for the convolution. </td></tr>
    <tr><td class="paramname">kernelSize</td><td>The HW-dimensions of the convolution kernel. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the convolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the convolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_convolution_layer.html" title="A convolution layer in a network definition. ">IConvolutionLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new convolution layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a80f985a0a5e5e68561ef205bf346fc33"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html">IDeconvolutionLayer</a>* nvinfer1::INetworkDefinition::addDeconvolution </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputMaps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>kernelSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a deconvolution layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">nbOutputMaps</td><td>The number of output feature maps. </td></tr>
    <tr><td class="paramname">kernelSize</td><td>The HW-dimensions of the convolution kernel. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the convolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the convolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html" title="A deconvolution layer in a network definition. ">IDeconvolutionLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new deconvolution layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="aa12fda7cb22a7a12f4d58701e9f3988f"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_element_wise_layer.html">IElementWiseLayer</a>* nvinfer1::INetworkDefinition::addElementWise </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a9badc834875b5c57d9556a66e5e20978">ElementWiseOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an elementwise layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input1</td><td>The first input tensor to the layer. </td></tr>
    <tr><td class="paramname">input2</td><td>The second input tensor to the layer. </td></tr>
    <tr><td class="paramname">op</td><td>The binary operation that the layer applies.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_element_wise_layer.html" title="A elementwise layer in a network definition. ">IElementWiseLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new elementwise layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a411e2cefb9a4307d99fcc442c2a708a8"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_fully_connected_layer.html">IFullyConnectedLayer</a>* nvinfer1::INetworkDefinition::addFullyConnected </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a fully connected layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">nbOutputs</td><td>The number of outputs of the layer. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the convolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the convolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_fully_connected_layer.html" title="A fully connected layer in a network definition. This layer expects an input tensor of three or more ...">IFullyConnectedLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new fully connected layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a81ea0b5ce4a6a24e8e4953fd0e0b3216"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_gather_layer.html">IGatherLayer</a>* nvinfer1::INetworkDefinition::addGather </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a gather layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>The tensor to gather values from. </td></tr>
    <tr><td class="paramname">indices</td><td>The tensor to get indices from to populate the output tensor. </td></tr>
    <tr><td class="paramname">axis</td><td>The non-batch dimension axis in the data tensor to gather on.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_gather_layer.html">IGatherLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new gather layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a06a61f560bdf6197afd3368937f62025"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a>* nvinfer1::INetworkDefinition::addInput </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217">DataType</a>&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>dimensions</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an input tensor to the network. </p>
<p>The name of the input tensor is used to find the index into the buffer array for an engine built from the network.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the tensor. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the data held in the tensor. </td></tr>
    <tr><td class="paramname">dimensions</td><td>The dimensions of the tensor.</td></tr>
  </table>
  </dd>
</dl>
<p>Only <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a2963c06d855a6b49f4b1abe2010e90b5" title="FP32 format. ">DataType::kFLOAT</a> and <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a67c1d9d7d355bd0be230f76e802c470a" title="FP16 format. ">DataType::kHALF</a> are valid input tensor types. The volume of the dimension, including the maximum batch size, must be less than 2^30 elements.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_tensor.html" title="A tensor in a network definition. ">ITensor</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new tensor or nullptr if there is an error. </dd></dl>

</div>
</div>
<a class="anchor" id="aa1c8386fd389fd74b0b48121d22abc67"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_l_r_n_layer.html">ILRNLayer</a>* nvinfer1::INetworkDefinition::addLRN </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>window</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>k</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a LRN layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">window</td><td>The size of the window. </td></tr>
    <tr><td class="paramname">alpha</td><td>The alpha value for the LRN computation. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta value for the LRN computation. </td></tr>
    <tr><td class="paramname">k</td><td>The k value for the LRN computation.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_l_r_n_layer.html" title="A LRN layer in a network definition. ">ILRNLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new LRN layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a434fd652b4b5d09cb2462d169d63044c"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html">IMatrixMultiplyLayer</a>* nvinfer1::INetworkDefinition::addMatrixMultiply </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>transpose0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>transpose1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a MatrixMultiply layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input0</td><td>The first input tensor (commonly A). </td></tr>
    <tr><td class="paramname">transpose0</td><td>If true, op(input0)=transpose(input0), else op(input0)=input0. </td></tr>
    <tr><td class="paramname">input1</td><td>The second input tensor (commonly B). </td></tr>
    <tr><td class="paramname">transpose1</td><td>If true, op(input1)=transpose(input1), else op(input1)=input1.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html" title="Layer that represents a Matrix Multiplication. ">IMatrixMultiplyLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new matrix multiply layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a334d849cb8720a8a66a95fc84487b132"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_padding_layer.html">IPaddingLayer</a>* nvinfer1::INetworkDefinition::addPadding </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>prePadding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>postPadding</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a padding layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">prePadding</td><td>The padding to apply to the start of the tensor. </td></tr>
    <tr><td class="paramname">postPadding</td><td>The padding to apply to the end of the tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_padding_layer.html" title="Layer that represents a padding operation. ">IPaddingLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>the new padding layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a4b31ce474ba291e1c95e39ab13c76942"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a>* nvinfer1::INetworkDefinition::addPlugin </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_plugin.html">IPlugin</a> &amp;&#160;</td>
          <td class="paramname"><em>plugin</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a plugin layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors. </td></tr>
    <tr><td class="paramname">plugin</td><td>The layer plugin.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_layer.html" title="Layer type for plugins. ">IPluginLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>the new plugin layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="ac1a2e299546ea7e803b88a4fdbd8f807"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a>* nvinfer1::INetworkDefinition::addPluginExt </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_plugin_ext.html">IPluginExt</a> &amp;&#160;</td>
          <td class="paramname"><em>plugin</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a plugin layer to the network using an <a class="el" href="classnvinfer1_1_1_i_plugin_ext.html" title="Plugin class for user-implemented layers. ">IPluginExt</a> interface. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors. </td></tr>
    <tr><td class="paramname">plugin</td><td>The layer plugin.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_layer.html" title="Layer type for plugins. ">IPluginLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new plugin layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a49459eaa7e1bbff5371365f125c2f0c5"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_pooling_layer.html">IPoolingLayer</a>* nvinfer1::INetworkDefinition::addPooling </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14">PoolingType</a>&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>windowSize</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a pooling layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">type</td><td>The type of pooling to apply. </td></tr>
    <tr><td class="paramname">windowSize</td><td>The size of the pooling window.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_pooling_layer.html" title="A Pooling layer in a network definition. ">IPoolingLayer</a> <a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14" title="The type of pooling to perform in a pooling layer. ">PoolingType</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new pooling layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="aea842c9f897201eb855ce164944e9110"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_ragged_soft_max_layer.html">IRaggedSoftMaxLayer</a>* nvinfer1::INetworkDefinition::addRaggedSoftMax </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>bounds</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a RaggedSoftMax layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The ZxS input tensor. </td></tr>
    <tr><td class="paramname">bounds</td><td>The Zx1 bounds tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_ragged_soft_max_layer.html" title="A RaggedSoftmax layer in a network definition. ">IRaggedSoftMaxLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new RaggedSoftMax layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a41437aa7107e61b82c5f3490984bf011"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_reduce_layer.html">IReduceLayer</a>* nvinfer1::INetworkDefinition::addReduce </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a6640220fcbd633240524ba27b5c6c7e7">ReduceOperation</a>&#160;</td>
          <td class="paramname"><em>operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>reduceAxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>keepDimensions</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a reduce layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">operation</td><td>The reduction operation to perform. </td></tr>
    <tr><td class="paramname">reduceAxes</td><td>The reduction dimensions. Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on. If a bit is set, then the corresponding dimension will be reduced. Let's say we have an NCHW tensor as input (three non-batch dimensions). Bit 0 corresponds to the C dimension boolean. Bit 1 corresponds to the H dimension boolean. Bit 2 corresponds to the W dimension boolean. Note that reduction is not permitted over the batch size dimension. </td></tr>
    <tr><td class="paramname">keepDimensions</td><td>The boolean that specifies whether or not to keep the reduced dimensions in the output of the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_reduce_layer.html" title="Layer that represents a reduction operator. ">IReduceLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new reduce layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a0ed8d1ed43046a041a90ad579fad5a20"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html">IRNNLayer</a>* nvinfer1::INetworkDefinition::addRNN </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>layerCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>hiddenSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>maxSeqLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fd">RNNInputMode</a>&#160;</td>
          <td class="paramname"><em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8">RNNDirection</a>&#160;</td>
          <td class="paramname"><em>dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>bias</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an <code>layerCount</code> deep RNN layer to the network with a sequence length of <code>maxSeqLen</code> and <code>hiddenSize</code> internal state per layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">layerCount</td><td>The number of layers in the RNN. </td></tr>
    <tr><td class="paramname">hiddenSize</td><td>The size of the internal hidden state for each layer. </td></tr>
    <tr><td class="paramname">maxSeqLen</td><td>The maximum length of the time sequence. </td></tr>
    <tr><td class="paramname">op</td><td>The type of RNN to execute. </td></tr>
    <tr><td class="paramname">mode</td><td>The input mode for the RNN. </td></tr>
    <tr><td class="paramname">dir</td><td>The direction to run the RNN. </td></tr>
    <tr><td class="paramname">weights</td><td>The weights for the weight matrix parameters of the RNN. </td></tr>
    <tr><td class="paramname">bias</td><td>The weights for the bias vectors parameters of the RNN.</td></tr>
  </table>
  </dd>
</dl>
<p>The input tensors must be of the type <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a2963c06d855a6b49f4b1abe2010e90b5" title="FP32 format. ">DataType::kFLOAT</a> or <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a67c1d9d7d355bd0be230f76e802c470a" title="FP16 format. ">DataType::kHALF</a>.</p>
<p>See <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html#a9333d560e68d49cbf60ba34d8872abf1" title="Set the weight parameters for the RNN. ">IRNNLayer::setWeights()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html#ae1a1d9599294c990d281a80ca684f1f0" title="Set the bias parameters for the RNN. ">IRNNLayer::setBias()</a> for details on the required input format for <code>weights</code> and <code>bias</code>.</p>
<p>The layout for the <code>input</code> tensor should be <code>{1, S_max, N, E}</code>, where:</p>
<ul>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>N</code> is the batch size</li>
<li><code>E</code> specifies the embedding length (unless <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fda903acc6373488fa3259402ba97e8b4fb" title="No operation is performed on the first recurrent layer. ">kSKIP</a> is set, in which case it should match getHiddenSize()).</li>
</ul>
<p>The first output tensor is the output of the final RNN layer across all timesteps, with dimensions <code>{S_max, N, H}</code>:</p>
<ul>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>N</code> is the batch size</li>
<li><code>H</code> is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())</li>
</ul>
<p>The second tensor is the final hidden state of the RNN across all layers, and if the RNN is an LSTM (i.e. getOperation() is <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200a2046aea763d568b2d5921641f57ec960" title="Four-gate LSTM network w/o peephole connections. ">kLSTM</a>), then the third tensor is the final cell state of the RNN across all layers. Both the second and third output tensors have dimensions <code>{L, N, H}</code>:</p>
<ul>
<li><code>L</code> is equal to getLayerCount() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a8599511603177311d4fc15c066f33461" title="Network iterations from first input to last input. ">kUNIDIRECTION</a>, and 2*getLayerCount() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a80c42616519e496e81b782101cd595af" title="Network iterates from first to last and vice versa and outputs concatenated. ">kBIDIRECTION</a>. In the bi-directional case, layer <code>l</code>'s final forward hidden state is stored in <code>L = 2*l</code>, and final backward hidden state is stored in <code>L = 2*l + 1</code>.</li>
<li><code>N</code> is the batch size</li>
<li><code>H</code> is getHiddenSize().</li>
</ul>
<p>Note that in bidirectional RNNs, the full "hidden state" for a layer <code>l</code> is the concatenation of its forward hidden state and its backward hidden state, and its size is 2*H.</p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000003">Deprecated:</a></b></dt><dd><a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html" title="A RNN layer in a network definition. ">IRNNLayer</a> is superseded by <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html" title="An RNN layer in a network definition, version 2. ">IRNNv2Layer</a>. Use <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6cd3869f7406f73261857987be1b18a9" title="Add an layerCount deep RNN layer to the network with hiddenSize internal states that can take a batch...">addRNNv2()</a> instead.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new RNN layer, or null if it could not be created. </dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html" title="A RNN layer in a network definition. ">IRNNLayer</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a6cd3869f7406f73261857987be1b18a9"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html">IRNNv2Layer</a>* nvinfer1::INetworkDefinition::addRNNv2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>layerCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>hiddenSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>maxSeqLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an <code>layerCount</code> deep RNN layer to the network with <code>hiddenSize</code> internal states that can take a batch with fixed or variable sequence lengths. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer (see below). </td></tr>
    <tr><td class="paramname">layerCount</td><td>The number of layers in the RNN. </td></tr>
    <tr><td class="paramname">hiddenSize</td><td>Size of the internal hidden state for each layer. </td></tr>
    <tr><td class="paramname">maxSeqLen</td><td>Maximum sequence length for the input. </td></tr>
    <tr><td class="paramname">op</td><td>The type of RNN to execute.</td></tr>
  </table>
  </dd>
</dl>
<p>By default, the layer is configured with <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a8599511603177311d4fc15c066f33461" title="Network iterations from first input to last input. ">RNNDirection::kUNIDIRECTION</a> and <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fdafd0bda8f85b35011bdcde415691fc36f" title="Perform the normal matrix multiplication in the first recurrent layer. ">RNNInputMode::kLINEAR</a>. To change these settings, use <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a9b941de0998d728accad69c61198fde7" title="Set the direction of the RNN layer. ">IRNNv2Layer::setDirection()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a0a7faa3f0e695ac6431bcccc12851954" title="Set the input mode of the RNN layer. ">IRNNv2Layer::setInputMode()</a>.</p>
<p>Weights and biases for the added layer should be set using <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#ac5e9205e8cb648b75bc918e92f55a2a6" title="Set the weight parameters for an individual gate in the RNN. ">IRNNv2Layer::setWeightsForGate()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a278902915200ab6c6b08c8f9671d6337" title="Set the bias parameters for an individual gate in the RNN. ">IRNNv2Layer::setBiasForGate()</a> prior to building an engine using this network.</p>
<p>The input tensors must be of the type <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a2963c06d855a6b49f4b1abe2010e90b5" title="FP32 format. ">DataType::kFLOAT</a> or <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a67c1d9d7d355bd0be230f76e802c470a" title="FP16 format. ">DataType::kHALF</a>. The layout of the weights is row major and must be the same datatype as the input tensor. <code>weights</code> contain 8 matrices and <code>bias</code> contains 8 vectors.</p>
<p>See <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#ac5e9205e8cb648b75bc918e92f55a2a6" title="Set the weight parameters for an individual gate in the RNN. ">IRNNv2Layer::setWeightsForGate()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a278902915200ab6c6b08c8f9671d6337" title="Set the bias parameters for an individual gate in the RNN. ">IRNNv2Layer::setBiasForGate()</a> for details on the required input format for <code>weights</code> and <code>bias</code>.</p>
<p>The <code>input</code> <a class="el" href="classnvinfer1_1_1_i_tensor.html" title="A tensor in a network definition. ">ITensor</a> should contain zero or more index dimensions <code>{N1, ..., Np}</code>, followed by two dimensions, defined as follows:</p>
<ul>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>E</code> specifies the embedding length (unless <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fda903acc6373488fa3259402ba97e8b4fb" title="No operation is performed on the first recurrent layer. ">kSKIP</a> is set, in which case it should match getHiddenSize()).</li>
</ul>
<p>By default, all sequences in the input are assumed to be size <code>maxSeqLen</code>. To provide explicit sequence lengths for each input sequence in the batch, use <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a8a29104927bc766971561eb8fbcbb3e8" title="Specify individual sequence lengths in the batch with the ITensor pointed to by seqLengths. ">IRNNv2Layer::setSequenceLengths()</a>.</p>
<p>The RNN layer outputs up to three tensors.</p>
<p>The first output tensor is the output of the final RNN layer across all timesteps, with dimensions <code>{N1, ..., Np, S_max, H}</code>:</p>
<ul>
<li><code>N1..Np</code> are the index dimensions specified by the input tensor</li>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>H</code> is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())</li>
</ul>
<p>The second tensor is the final hidden state of the RNN across all layers, and if the RNN is an LSTM (i.e. getOperation() is <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200a2046aea763d568b2d5921641f57ec960" title="Four-gate LSTM network w/o peephole connections. ">kLSTM</a>), then the third tensor is the final cell state of the RNN across all layers. Both the second and third output tensors have dimensions <code>{N1, ..., Np, L, H}</code>:</p>
<ul>
<li><code>N1..Np</code> are the index dimensions specified by the input tensor</li>
<li><code>L</code> is the number of layers in the RNN, equal to getLayerCount()</li>
<li><code>H</code> is the hidden state for each layer, equal to getHiddenSize() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a8599511603177311d4fc15c066f33461" title="Network iterations from first input to last input. ">kUNIDIRECTION</a>, and 2x getHiddenSize() otherwise.</li>
</ul>
<dl class="section return"><dt>Returns</dt><dd>The new RNN layer, or null if it could not be created. </dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html" title="An RNN layer in a network definition, version 2. ">IRNNv2Layer</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a37cf24c7c620aa661de167f302559289"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_scale_layer.html">IScaleLayer</a>* nvinfer1::INetworkDefinition::addScale </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0">ScaleMode</a>&#160;</td>
          <td class="paramname"><em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>power</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a Scale layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to The layer. This tensor is required to have a minimum of 3 dimensions. </td></tr>
    <tr><td class="paramname">mode</td><td>The scaling mode. </td></tr>
    <tr><td class="paramname">shift</td><td>The shift value. </td></tr>
    <tr><td class="paramname">scale</td><td>The scale value. </td></tr>
    <tr><td class="paramname">power</td><td>The power value.</td></tr>
  </table>
  </dd>
</dl>
<p>If the weights are available, then the size of weights are dependent on the on the ScaleMode. For <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0a1f65127b6291c007dd952d4ebc39b1bf" title="Identical coefficients across all elements of the tensor. ">kUNIFORM</a>, the number of weights is equal to 1. For <a class="el" href="namespacenvinfer1.html#ab4e600f818644bb418e0a5356bf43dd9afbf2bd146f6f86d9ab02397d16eca973" title="Elements correspond to different channels. ">kCHANNEL</a>, the number of weights is equal to the channel dimension. For <a class="el" href="namespacenvinfer1.html#a6fd444d95c9f8dcf9d87771b6d3c863dabf7aa33cd17f025808e60f6e1690fd11" title="Elementwise layer. ">kELEMENTWISE</a>, the number of weights is equal to the volume of the input.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_scale_layer.html" title="A Scale layer in a network definition. ">IScaleLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new Scale layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a2628a97544b7802076246069321e2bf9"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_shuffle_layer.html">IShuffleLayer</a>* nvinfer1::INetworkDefinition::addShuffle </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a shuffle layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The new shuffle layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a595af67528bf0664afa9815114933320"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_soft_max_layer.html">ISoftMaxLayer</a>* nvinfer1::INetworkDefinition::addSoftMax </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a SoftMax layer to the network. </p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_soft_max_layer.html" title="A Softmax layer in a network definition. ">ISoftMaxLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new SoftMax layer, or null if it could not be created. </dd></dl>

</div>
</div>
<a class="anchor" id="a384a409318bf416be3aa4442f2b0ce76"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_top_k_layer.html">ITopKLayer</a>* nvinfer1::INetworkDefinition::addTopK </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a1323342950a2702ba66e29c64404a7f3">TopKOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>reduceAxes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a TopK layer to the network. </p>
<p>The TopK layer has two outputs of the same dimensions. The first contains data values, the second contains index positions for the values. Output values are sorted, largest first for operation kMAX and smallest first for operation kMIN.</p>
<p>Currently only values of K up to 1024 are supported.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
    <tr><td class="paramname">op</td><td>Operation to perform.</td></tr>
    <tr><td class="paramname">k</td><td>Number of elements to keep.</td></tr>
    <tr><td class="paramname">reduceAxes</td><td>The reduction dimensions. Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on. If a bit is set, then the corresponding dimension will be reduced. Let's say we have an NCHW tensor as input (three non-batch dimensions). Bit 0 corresponds to the C dimension boolean. Bit 1 corresponds to the H dimension boolean. Bit 2 corresponds to the W dimension boolean. Note that TopK reduction is currently only permitted over one dimension. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a4b85bd3f05c234fcc1118f827d7c0720"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_unary_layer.html">IUnaryLayer</a>* nvinfer1::INetworkDefinition::addUnary </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aeaeaae08a730508ead278d52b8517a09">UnaryOperation</a>&#160;</td>
          <td class="paramname"><em>operation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a unary layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">operation</td><td>The operation to apply.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_unary_layer.html" title="Layer that represents an unary operation. ">IUnaryLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new unary layer, or null if it could not be created </dd></dl>

</div>
</div>
<a class="anchor" id="a355de31bece2776d8ca5866ad38db40f"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a>&amp; nvinfer1::INetworkDefinition::getConvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the convolution output dimensions formula. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000005">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The formula from computing the convolution output dimensions.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa5516b9c8061a0d44ef13568637a173a" title="Set the convolution output dimensions formula. ">setConvolutionOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a0470c5b3b58464083ed2d10ed52c2049"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a>&amp; nvinfer1::INetworkDefinition::getDeconvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the deconvolution output dimensions formula. </p>
<dl class="section return"><dt>Returns</dt><dd>The formula from computing the deconvolution output dimensions.</dd></dl>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000007">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac9d58a40de209963d4ea5e733c9b16c1" title="Set the deconvolution output dimensions formula. ">setDeconvolutionOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="aaecdd8775e0ce4643112932f721f93c1"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a>* nvinfer1::INetworkDefinition::getInput </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the input tensor specified by the given index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the input tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The input tensor, or null if the index is out of range.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac7a0538c92b9850b3ecd939609759cdd" title="Get the number of inputs in the network. ">getNbInputs()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a4a81749aaa08e93ca4ae1dbb1739c7bd"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_layer.html">ILayer</a>* nvinfer1::INetworkDefinition::getLayer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the layer specified by the given index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The layer, or null if the index is out of range.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a191a7724fc0c03a3b6f5fd8782dcd30e" title="Get the number of layers in the network. ">getNbLayers()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="ac7a0538c92b9850b3ecd939609759cdd"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int nvinfer1::INetworkDefinition::getNbInputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of inputs in the network. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of inputs in the network.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aaecdd8775e0ce4643112932f721f93c1" title="Get the input tensor specified by the given index. ">getInput()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a191a7724fc0c03a3b6f5fd8782dcd30e"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int nvinfer1::INetworkDefinition::getNbLayers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of layers in the network. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of layers in the network.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4a81749aaa08e93ca4ae1dbb1739c7bd" title="Get the layer specified by the given index. ">getLayer()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a1eb3e1df9e652363d7ab4e3796794bb2"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int nvinfer1::INetworkDefinition::getNbOutputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of outputs in the network. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of outputs in the network.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6eb45e378bf2b2097da64e3886010bd0" title="Get the output tensor specified by the given index. ">getOutput()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a6eb45e378bf2b2097da64e3886010bd0"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a>* nvinfer1::INetworkDefinition::getOutput </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the output tensor specified by the given index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the output tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor, or null if the index is out of range.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a1eb3e1df9e652363d7ab4e3796794bb2" title="Get the number of outputs in the network. ">getNbOutputs()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a6700a429213bf8ae37472ca5b687dbb2"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a>&amp; nvinfer1::INetworkDefinition::getPoolingOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the pooling output dimensions formula. </p>
<dl class="section return"><dt>Returns</dt><dd>The formula from computing the pooling output dimensions.</dd></dl>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#ad8311e3c0c99f0d058bc195b0f8f4878" title="Set the pooling output dimensions formula. ">setPoolingOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="a5d2cdec24bc4a1507fc80f100e18cfe9"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::markOutput </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Mark a tensor as a network output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to mark as an output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aa5516b9c8061a0d44ef13568637a173a"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::setConvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *&#160;</td>
          <td class="paramname"><em>formula</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the convolution output dimensions formula. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000004">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">formula</td><td>The formula from computing the convolution output dimensions. If null is passed, the default formula is used.</td></tr>
  </table>
  </dd>
</dl>
<p>The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a355de31bece2776d8ca5866ad38db40f" title="Get the convolution output dimensions formula. ">getConvolutionOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a class="anchor" id="ac9d58a40de209963d4ea5e733c9b16c1"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::setDeconvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *&#160;</td>
          <td class="paramname"><em>formula</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the deconvolution output dimensions formula. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000006">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">formula</td><td>The formula from computing the deconvolution output dimensions. If null is passed, the default formula is used.</td></tr>
  </table>
  </dd>
</dl>
<p>The default formula in each dimension is (inputDim - 1) * stride + kernelSize - 2 * padding.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> getDevonvolutionOutputDimensionsFormula() </dd></dl>

</div>
</div>
<a class="anchor" id="ad8311e3c0c99f0d058bc195b0f8f4878"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::setPoolingOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *&#160;</td>
          <td class="paramname"><em>formula</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the pooling output dimensions formula. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">formula</td><td>The formula from computing the pooling output dimensions. If null is passed, the default formula is used.</td></tr>
  </table>
  </dd>
</dl>
<p>The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6700a429213bf8ae37472ca5b687dbb2" title="Get the pooling output dimensions formula. ">getPoolingOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="_nv_infer_8h_source.html">NvInfer.h</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacenvinfer1.html">nvinfer1</a></li><li class="navelem"><a class="el" href="classnvinfer1_1_1_i_network_definition.html">INetworkDefinition</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.6 </li>
  </ul>
</div>
</body>
</html>
